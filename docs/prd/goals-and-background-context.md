# Goals and Background Context

## Project Name

PPO to Hierarchical Reasoning Model (HRM) Migration for Algorithmic Trading System

## Goals

1. **Replace PPO Architecture**: Transition from online PPO reinforcement learning to brain-inspired Hierarchical Reasoning Model (HRM)
2. **Hierarchical Multi-Timescale Processing**: Implement H-module (strategic) and L-module (tactical) for natural trading hierarchy
3. **Revolutionary Efficiency**: Achieve superior performance with only 27M parameters vs traditional billion-parameter models
4. **Adaptive Computation Time**: Dynamic reasoning depth based on market complexity and volatility
5. **Internal Reasoning**: Enable latent reasoning without Chain-of-Thought overhead for real-time trading decisions

## Background

The current algorithmic trading system uses PPO (Proximal Policy Optimization) with transformer-based Actor-Critic models. While functional, this approach has limitations:

- Limited computational depth due to fixed architecture
- Massive parameter requirements for reasonable performance
- Online learning instability and sample inefficiency
- Lack of hierarchical reasoning across trading timescales
- Missing adaptive computation for varying market complexity

Hierarchical Reasoning Model (HRM) represents a breakthrough in neural architecture, offering brain-inspired hierarchical processing, unlimited computational depth through hierarchical convergence, and revolutionary efficiency (27M parameters achieving performance of billion-parameter models). HRM's two-module design naturally maps to trading's strategic/tactical decision hierarchy.

## Change Log

- **v1.0**: Initial PPO implementation with transformer models
- **v2.0** (Proposed): Hierarchical Reasoning Model (HRM) with brain-inspired dual-module architecture
