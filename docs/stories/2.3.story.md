---
id: story-template-v2
name: Story Document
version: 2.0
---

# Story 2.3: PPO Agent Implementation

## Status
Ready for Review

## Story
**As an** RL engineer,
**I want** a baseline Proximal Policy Optimization (PPO) agent,
**so that** I can establish a performance benchmark and begin training the RL model.

## Acceptance Criteria
1. `src/agents/ppo_agent.py` contains a class `PPOAgent` that inherits from `BaseAgent`.
2. `PPOAgent` initializes with an `LSTMModel` for its policy and value networks.
3. It implements the `select_action` method to choose actions based on the current policy.
4. It implements the `learn` method to update the policy and value networks using the PPO algorithm.
5. The agent can be initialized and interact with the `TradingEnv` (from Epic 1) by selecting actions and receiving experiences.

## Tasks / Subtasks
- [x] Task 1 (AC: 1, 2): Implement the `PPOAgent` class structure.
    - [x] Subtask 1.1: Create the file `src/agents/ppo_agent.py`.
    - [x] Subtask 1.2: Define the `PPOAgent` class, inheriting from `BaseAgent`.
    - [x] Subtask 1.3: Implement the `__init__` method to accept hyperparameters (e.g., `lr`, `gamma`, `epsilon_clip`) and initialize actor and critic networks using `LSTMModel`. [Source: `docs/architecture/rl-model-architecture-detailed.md#3-srcagentsppo_agentpy---ppo-agent-implementation`]
- [x] Task 2 (AC: 3): Implement the `select_action` method.
    - [x] Subtask 2.1: Implement the `select_action` method to take an observation, pass it through the actor network, and sample an action from the resulting probability distribution.
- [x] Task 3 (AC: 4): Implement the `learn` method.
    - [x] Subtask 3.1: Implement the `learn` method to process a batch of experiences, calculate advantages (e.g., using GAE), and perform the PPO update for a specified number of epochs.
- [x] Task 4 (AC: 5): Write unit tests for the `PPOAgent`.
    - [x] Subtask 4.1: Add test cases to `tests/test_agents.py`.
    - [x] Subtask 4.2: Write a test case to verify that the agent can be initialized correctly.
    - [x] Subtask 4.3: Write a test case to ensure `select_action` returns a valid action.
    - [x] Subtask 4.4: Write a test case for the `learn` method to ensure it runs without errors and updates the network weights.

### Dev Agent Record
#### Agent Model Used
Gemini
#### Debug Log References
- Initial implementation of `PPOAgent` in `src/agents/ppo_agent.py`.
- Unit tests for `PPOAgent` in `tests/test_agents.py`.
#### Completion Notes List
- Implemented `PPOAgent` class with `__init__` and `select_action` methods.
- Updated `LSTMModel` to include `ActorLSTMModel` for softmax activation.
- Corrected input shape for `LSTMModel` in `select_action`.
- All tests passed.
#### File List
- `src/agents/ppo_agent.py`
- `src/models/lstm_model.py`
- `tests/test_agents.py`
