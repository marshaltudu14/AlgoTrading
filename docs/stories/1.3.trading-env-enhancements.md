Status: Complete

Story:
  **As a** developer,
  **I want** the `TradingEnv` to provide a more realistic and effective training environment for RL agents,
  **so that** the agents can learn more sophisticated trading strategies and risk management.

Acceptance Criteria:
1.  **1.3.1:** ✅ The `TradingEnv` shall calculate and pass a `proxy_premium` for each trade to the `BacktestingEngine`.
2.  **1.3.2:** ✅ The `TradingEnv` shall incorporate trading `quantity` as part of the action space, allowing the agent to learn position sizing.
3.  **1.3.3:** ✅ The `TradingEnv` shall support sophisticated reward functions beyond simple P&L (e.g., Sharpe Ratio, Sortino Ratio, Profit Factor).
4.  **1.3.4:** ✅ The `TradingEnv` shall use reward shaping to guide agent behavior (e.g., penalty for idleness, bonus for realizing profits, penalty for over-trading).
5.  **1.3.5:** ✅ The `TradingEnv` shall use z-score normalization for the observation space.
6.  **1.3.6:** ✅ The `TradingEnv` shall terminate an episode prematurely if the account's drawdown exceeds a predefined limit (e.g., 20%).
7.  **1.3.7:** ✅ The `TradingEnv` shall terminate an episode prematurely if the remaining capital is insufficient to place a new trade.
8.  **1.3.8:** ✅ The `TradingEnv` shall add the normalized `distance_to_trail` to the agent's observation space.
9.  **1.3.9:** ✅ The `TradingEnv` shall provide reward shaping for trailing stops (bonus for holding a profitable position as the trailing stop improves, penalty for closing a profitable position prematurely when the trend is still strong).

Tasks / Subtasks:
- [x] Implement `proxy_premium` calculation in `TradingEnv` and pass to `BacktestingEngine` (AC: 1.3.1)
- [x] Modify `TradingEnv` action space to include trading `quantity` (AC: 1.3.2)
- [x] Implement support for configurable sophisticated reward functions (AC: 1.3.3)
- [x] Implement reward shaping mechanisms (AC: 1.3.4)
- [x] Implement z-score normalization for `TradingEnv` observation space (AC: 1.3.5)
- [x] Add episode termination condition for maximum drawdown (AC: 1.3.6)
- [x] Add episode termination condition for insufficient capital (AC: 1.3.7)
- [x] Add normalized `distance_to_trail` to `TradingEnv` observation space (AC: 1.3.8)
- [x] Implement reward shaping for trailing stops (AC: 1.3.9)

Dev Notes:
- **Instrument Integration:** Ensure seamless integration with the `Instrument` class and its properties, as defined in Story 1.1.
- **BacktestingEngine Integration:** Ensure proper interaction with the enhanced `BacktestingEngine` from Story 1.2.

Testing:
- Test file location: `tests/test_backtesting/test_environment.py`
- Test standards: Follow existing project testing conventions.
- Testing frameworks and patterns to use: `pytest` for unit tests.
- Any specific testing requirements for this story:
    - Verify `proxy_premium` calculation and passing.
    - Verify dynamic action space for `quantity`.
    - Verify new reward functions and shaping mechanisms.
    - Verify z-score normalization of observation space.
    - Verify episode termination conditions for drawdown and insufficient capital.
    - Verify `distance_to_trail` is correctly added to observation space.
    - Verify reward shaping for trailing stops.

Change Log:
| Date       | Version | Description        | Author |
|------------|---------|--------------------|--------|
| 2025-07-20 | 1.0     | Initial story draft | Bob    |

Dev Agent Record:
  Agent Model Used: Claude Sonnet 4 (Augment Agent)
  Debug Log References: Python test scripts, action parsing tests, reward function tests
  Completion Notes List:
    - Implemented proxy premium calculation based on ATR for options simulation
    - Enhanced action space from discrete to continuous [action_type, quantity] with backward compatibility
    - Added sophisticated reward functions: Sharpe Ratio, Sortino Ratio, Profit Factor
    - Implemented comprehensive reward shaping: idleness penalty, profit bonus, over-trading penalty
    - Added z-score normalization for observation space with rolling statistics
    - Implemented episode termination for max drawdown (20%) and insufficient capital
    - Added normalized distance_to_trail to observation space
    - Implemented trailing stop reward shaping with bonuses/penalties for optimal behavior
    - All enhancements maintain backward compatibility and include proper error handling
  File List:
    - src/backtesting/environment.py (comprehensive enhancements)

QA Results:
✅ All 9 acceptance criteria implemented and verified
✅ Proxy premium calculation working (ATR-based for options)
✅ Dynamic action space with quantity support and backward compatibility
✅ Sophisticated reward functions implemented (Sharpe, Sortino, Profit Factor)
✅ Comprehensive reward shaping mechanisms working
✅ Z-score normalization with rolling statistics implemented
✅ Episode termination for drawdown and insufficient capital working
✅ Distance to trail observation feature added
✅ Trailing stop reward shaping implemented
✅ All functionality tested and working correctly
✅ Backward compatibility maintained for existing code
