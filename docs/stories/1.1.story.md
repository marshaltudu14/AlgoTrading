---
epic: 1
story: 1
title: Implement MVP Data Processing to Model Prediction Pipeline
status: Approved
---

### Story

As a trading system operator, I want to process raw market data, train a supervised model using that data, and then use the trained model to generate a prediction for a live market data point, so that I can validate the end-to-end flow of the autonomous trading bot.

### Acceptance Criteria

*   **AC 1**: Given raw market data, the data processing pipeline successfully generates features and reasoning data.
*   **AC 2**: Given the processed data, the supervised model pipeline successfully trains a model and saves it.
*   **AC 3**: The trained model can be loaded and used to generate a prediction for a single, new live market data point.
*   **AC 4**: The prediction for the live market data point is logged or displayed.

### Dev Notes

*   **Previous Story Insights**: This is the first story, so no previous insights.
*   **Data Models**:
    *   Raw data: `datetime`, `open`, `high`, `low`, `close` (volume is dropped if present). [Source: mainIdea.md#raw-data-sources]
    *   Processed data (features): Includes various technical indicators, market structure, candlestick patterns, and price action features generated by `src/data_processing/feature_generator.py`. [Source: src/data_processing/feature_generator.py]
    *   Reasoning data: Adds `reasoning` and `decision` columns generated by the `src/reasoning_system/core/enhanced_orchestrator.py` (via `src/data_processing/pipeline.py`). [Source: src/data_processing/pipeline.py]
    *   Supervised model input: Numerical features from processed data combined with embeddings of the `reasoning` column. [Source: src/supervised_model/model_pipeline.py]
*   **API Specifications**: No specific API specifications from architecture docs. The existing `data_processing/pipeline.py` and `supervised_model/model_pipeline.py` define the internal APIs.
*   **Component Specifications**: No specific component specifications from architecture docs.
*   **File Locations**:
    *   Raw data input: `data/raw/` [Source: docs/architecture/source-tree.md#data-directory-data]
    *   Processed data (features): `data/processed/` [Source: docs/architecture/source-tree.md#data-directory-data]
    *   Processed data (reasoning): `data/processed/reasoning/` [Source: docs/architecture/source-tree.md#data-directory-data]
    *   Final training data: `data/final/` [Source: docs/architecture/source-tree.md#data-directory-data]
    *   Trained model, scaler, label encoder: `models/` [Source: docs/architecture/source-tree.md#models-directory-models]
    *   Hugging Face tokenizer/model: `models/hf_tokenizer`, `models/hf_model` [Source: docs/architecture/source-tree.md#models-directory-models]
    *   Live predictor script: `scripts/live_predictor.py` [Source: docs/architecture/source-tree.md#scripts-directory-scripts]
*   **Testing Requirements**: Unit tests for individual functions/methods, integration tests for component interactions, and end-to-end tests for the full pipeline. [Source: docs/architecture/coding-standards.md#testing]
*   **Technical Constraints**: No specific guidance found in architecture docs.
*   **Coding Standards**: Adhere to PEP 8, use docstrings, type hinting, and proper import organization. Use `logging` for application logs. [Source: docs/architecture/coding-standards.md#python-specific-standards]
*   **Tech Stack**: Python with Pandas, NumPy, Scikit-learn, PyTorch, Hugging Face Transformers, joblib, and pandas-ta. [Source: docs/architecture/tech-stack.md#technology-stack]
*   **Source Tree**: Follow the defined project structure for file and directory placement. [Source: docs/architecture/source-tree.md#project-source-tree]

### Tasks / Subtasks

- [ ] **Task 1: Ensure Data Processing Pipeline is Functional (AC 1)**
    - [ ] Subtask 1.1: Verify `src/data_processing/feature_generator.py` correctly generates all features from raw data. [Source: src/data_processing/feature_generator.py]
    - [ ] Subtask 1.2: Verify `src/data_processing/pipeline.py` orchestrates feature generation and reasoning generation. [Source: src/data_processing/pipeline.py]
    - [ ] Subtask 1.3: Ensure `data/raw` contains sample CSV files for testing. [Source: docs/architecture/source-tree.md#data-directory-data]
    - [ ] Subtask 1.4: Run the data processing pipeline and confirm `data/final` contains processed files with features and reasoning. [Source: src/data_processing/pipeline.py]
        - [ ] `python src/data_processing/pipeline.py`
- [ ] **Task 2: Verify Supervised Model Training (AC 2)**
    - [ ] Subtask 2.1: Verify `src/supervised_model/model_pipeline.py` loads processed data from `data/final`. [Source: src/supervised_model/model_pipeline.py]
    - [ ] Subtask 2.2: Confirm `model_pipeline.py` correctly prepares data (scaling, embedding reasoning column). [Source: src/supervised_model/model_pipeline.py]
    - [ ] Subtask 2.3: Ensure `model_pipeline.py` trains a model and saves it to `models/supervised_model.joblib`, `models/scaler.joblib`, and `models/label_encoder.joblib`. [Source: src/supervised_model/model_pipeline.py]
    - [ ] Subtask 2.4: Run the model training script and confirm model artifacts are saved. [Source: src/supervised_model/model_pipeline.py]
        - [ ] `python src/supervised_model/model_pipeline.py`
- [ ] **Task 3: Implement Live Prediction Functionality (AC 3, AC 4)**
    - [ ] Subtask 3.1: Create a new script `scripts/live_predictor.py` to load the trained model and its components (scaler, label encoder, HF models). [Source: docs/architecture/source-tree.md#scripts-directory-scripts]
    - [ ] Subtask 3.2: In `scripts/live_predictor.py`, implement a function to simulate receiving a single, new live market data point (e.g., a dictionary or small DataFrame with OHLC and other required features). [Source: docs/architecture/tech-stack.md#data-sources--apis]
    - [ ] Subtask 3.3: Adapt the data preparation logic from `model_pipeline.py` to process this single live data point, including feature generation and reasoning embedding. [Source: src/supervised_model/model_pipeline.py]
    - [ ] Subtask 3.4: Use the loaded supervised model to generate a prediction for the live data point. [Source: src/supervised_model/model_pipeline.py]
    - [ ] Subtask 3.5: Log or print the prediction to the console. [Source: docs/architecture/coding-standards.md#logging]
- [ ] **Task 4: End-to-End Integration Test**
    - [ ] Subtask 4.1: Create a test script `scripts/testing/test_mvp_pipeline.py` that orchestrates the full flow:
        - [ ] Run data processing pipeline (Task 1).
        - [ ] Run model training pipeline (Task 2).
        - [ ] Run live prediction script with a sample data point (Task 3).
    - [ ] Subtask 4.2: Assert that the prediction is generated without errors. [Source: docs/architecture/coding-standards.md#testing]

### Dev Agent Record

#### Agent Model Used

#### Debug Log References

#### Completion Notes List

#### File List

#### Change Log

### QA Results

### Status

Draft
