Status: Draft

Story:
  **As a** developer,
  **I want** the `Trainer` to fully implement the meta-optimization logic,
  **so that** the `MoEAgent`'s meta-parameters can be updated based on meta-loss accumulated across tasks.

Acceptance Criteria:
1.  **2.3.1:** The critical "outer loop meta-update" in `Trainer.meta_train` shall be fully implemented, enabling the meta-optimization of the `MoEAgent`.

Tasks / Subtasks:
- [ ] Implement the outer loop meta-update logic in `Trainer.meta_train` (AC: 2.3.1)
- [ ] Ensure `Trainer.meta_train` correctly updates the `MoEAgent`'s meta-parameters based on meta-loss.

Dev Notes:
- **Meta-Optimization:** The outer loop meta-update is crucial for the MAML algorithm, allowing the `MoEAgent` to learn how to quickly adapt to new tasks.
- **Integration:** This task relies on the completed `learn` and `adapt` methods of the `MoEAgent` (Story 2.2) and the specialized agents (Story 2.1).

Testing:
- Test file location: `tests/test_training/test_trainer.py`
- Test standards: Follow existing project testing conventions.
- Testing frameworks and patterns to use: `pytest` for unit tests.
- Any specific testing requirements for this story:
    - Verify that `Trainer.meta_train` executes the outer loop meta-update.
    - Verify that the `MoEAgent`'s meta-parameters are updated after meta-training.

Change Log:
| Date       | Version | Description        | Author |
|------------|---------|--------------------|--------|
| 2025-07-20 | 1.0     | Initial story draft | Bob    |

Dev Agent Record:
  Agent Model Used:
  Debug Log References:
  Completion Notes List:
  File List:

QA Results:
