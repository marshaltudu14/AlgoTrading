---
id: story-template-v2
name: Story Document
version: 2.0
---

# Story 2.4: RL Training Loop

## Status
Draft

## Story
**As an** RL engineer,
**I want** a training script that orchestrates the learning process,
**so that** I can train the PPO agent within the backtesting environment.

## Acceptance Criteria
1. `src/training/trainer.py` contains a `Trainer` class or function.
2. The `Trainer` can be initialized with a `TradingEnv` instance and a `PPOAgent` instance.
3. It implements a training loop that:
    - Resets the environment for each episode.
    - Interacts with the environment by calling `agent.select_action()` and `env.step()`.
    - Collects experiences (`(state, action, reward, next_state, done)`).
    - Calls `agent.learn()` periodically to update the agent's policy.
    - Logs training progress (e.g., episode rewards, losses) to the terminal.
4. The training loop can run for a specified number of episodes.
5. The `Trainer` can save the trained agent's model at the end of training.

## Tasks / Subtasks
- [ ] Task 1 (AC: 1, 2): Implement the `Trainer` class structure.
    - [ ] Subtask 1.1: Create the file `src/training/trainer.py`.
    - [ ] Subtask 1.2: Define the `Trainer` class with an `__init__` method that accepts an environment, an agent, and training parameters (e.g., `num_episodes`). [Source: `docs/architecture/rl-model-architecture-detailed.md#4-srctrainingtrainerpy---rl-training-loop`]
- [ ] Task 2 (AC: 3, 4): Implement the main training loop.
    - [ ] Subtask 2.1: Implement the `train` method, which contains the main loop for running episodes.
    - [ ] Subtask 2.2: Inside the loop, interact with the environment to collect a buffer of experiences.
    - [ ] Subtask 2.3: Call the agent's `learn` method with the collected experiences.
    - [ ] Subtask 2.4: Implement logging to print progress to the terminal.
- [ ] Task 3 (AC: 5): Implement model saving.
    - [ ] Subtask 3.1: Add a call to `agent.save_model()` at the end of the training loop.
- [ ] Task 4: Write integration tests for the `Trainer`.
    - [ ] Subtask 4.1: Create a test file `tests/test_training.py`.
    - [ ] Subtask 4.2: Write an integration test that initializes a `Trainer` with a mock `TradingEnv` and a mock `PPOAgent` and runs the training loop for a small number of episodes.

## Dev Notes
- **File Location**: `src/training/trainer.py` [Source: `docs/architecture/source-tree.md#6-source-directory-src`]
- **Class**: `Trainer`
- **Responsibilities**: This class orchestrates the entire training process, from interacting with the environment to telling the agent when to learn. [Source: `docs/architecture/rl-model-architecture-detailed.md#4-srctrainingtrainerpy---rl-training-loop`]

### Testing
- An integration test should be created in a new file `tests/test_training.py`.
- The test should verify that the training loop runs without errors and that the agent's `learn` and `save_model` methods are called.

## QA Results
