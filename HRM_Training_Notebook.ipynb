{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHZCW0Nz67OW"
      },
      "source": [
        "# HRM (Hierarchical Reasoning Model) Trading Training on Colab/Kaggle\n",
        "\n",
        "This notebook converts the HRM training pipeline to run on Google Colab or Kaggle notebooks with automatic TPU/GPU/CPU detection.\n",
        "\n",
        "## Overview\n",
        "- **HRM Architecture**: Brain-inspired hierarchical model with 27M parameters\n",
        "- **Training Approach**: Deep supervision with adaptive computation time\n",
        "- **Data Processing**: Automated pipeline from raw to training-ready data\n",
        "- **Hardware Support**: Automatic TPU/GPU/CPU detection with parallel training\n",
        "\n",
        "Based on the research paper: *Hierarchical Reasoning Model* by Guan Wang et al."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZormcV-r67OY"
      },
      "source": [
        "## 1. Setup Environment and Clone Repository\n",
        "\n",
        "Clone the private GitHub repository using the service token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyI6gCpQ67OY",
        "outputId": "4254b0dd-be78-4520-eb55-39fd9ceeae60"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "# Detect runtime environment\n",
        "def is_colab():\n",
        "    return \"COLAB_GPU\" in os.environ\n",
        "\n",
        "def is_kaggle():\n",
        "    return \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ\n",
        "\n",
        "def check_tpu_availability():\n",
        "    try:\n",
        "        import requests\n",
        "        response = requests.get(\n",
        "            'http://metadata.google.internal/computeMetadata/v1/instance/attributes/accelerator-type',\n",
        "            headers={'Metadata-Flavor': 'Google'},\n",
        "            timeout=5\n",
        "        )\n",
        "        return 'tpu' in response.text.lower()\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "in_cloud_env = is_colab() or is_kaggle()\n",
        "is_tpu_environment = check_tpu_availability() if in_cloud_env else False\n",
        "\n",
        "print(f\"ğŸ” Running in Colab: {is_colab()} | Kaggle: {is_kaggle()} | TPU: {is_tpu_environment}\")\n",
        "\n",
        "# Repo details\n",
        "repo_url = \"https://{personal_access_token}@github.com/marshaltudu14/AlgoTrading.git\"\n",
        "repo_path = \"/content/AlgoTrading\"\n",
        "\n",
        "if in_cloud_env or is_tpu_environment:\n",
        "    # Clone repository only if running in cloud\n",
        "    if not os.path.exists(repo_path):\n",
        "        print(\"ğŸ“¥ Cloning AlgoTrading repository...\")\n",
        "        result = subprocess.run(\n",
        "            [\"git\", \"clone\", repo_url, repo_path],\n",
        "            capture_output=True, text=True\n",
        "        )\n",
        "        if result.returncode == 0:\n",
        "            print(\"âœ… Repository cloned successfully!\")\n",
        "        else:\n",
        "            print(f\"âŒ Failed to clone repository: {result.stderr}\")\n",
        "            raise Exception(\"Repository clone failed\")\n",
        "    else:\n",
        "        print(\"âœ… Repository already exists\")\n",
        "\n",
        "    # Change to repository directory\n",
        "    os.chdir(repo_path)\n",
        "    sys.path.append(repo_path)\n",
        "\n",
        "    print(f\"ğŸ“ Current directory: {os.getcwd()}\")\n",
        "    print(f\"ğŸ“‹ Repository contents:\")\n",
        "    for item in sorted(os.listdir('.')):\n",
        "        print(f\"  {item}\")\n",
        "else:\n",
        "    print(\"â­ï¸ Local environment detected. Skipping repository cloning.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbKvHB-C67OZ"
      },
      "source": [
        "## 2. Install Dependencies\n",
        "\n",
        "Install all required packages including TPU support for Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1Q0AkMDj67Oa",
        "outputId": "a9f17757-708f-4422-96a2-dfe1cae870d1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Detect runtime environment\n",
        "def is_colab():\n",
        "    return \"COLAB_GPU\" in os.environ\n",
        "\n",
        "def is_kaggle():\n",
        "    return \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ\n",
        "\n",
        "def check_tpu_availability():\n",
        "    try:\n",
        "        import requests\n",
        "        response = requests.get(\n",
        "            'http://metadata.google.internal/computeMetadata/v1/instance/attributes/accelerator-type',\n",
        "            headers={'Metadata-Flavor': 'Google'},\n",
        "            timeout=5\n",
        "        )\n",
        "        return 'tpu' in response.text.lower()\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "in_cloud_env = is_colab() or is_kaggle()\n",
        "is_tpu_environment = check_tpu_availability() if in_cloud_env else False\n",
        "\n",
        "print(f\"ğŸ” Running in Colab: {is_colab()} | Kaggle: {is_kaggle()} | TPU: {is_tpu_environment}\")\n",
        "\n",
        "# Install only if in cloud (Colab/Kaggle/TPU)\n",
        "if in_cloud_env or is_tpu_environment:\n",
        "    print(\"ğŸ“¦ Installing base requirements...\")\n",
        "    !pip install -r requirements.txt\n",
        "\n",
        "    if is_tpu_environment:\n",
        "        print(\"ğŸš€ Installing TPU support...\")\n",
        "        !pip install torch_xla cloud-tpu-client\n",
        "\n",
        "    print(\"ğŸ“Š Installing visualization libraries...\")\n",
        "    !pip install ipywidgets plotly kaleido\n",
        "\n",
        "    print(\"âœ… All dependencies installed successfully!\")\n",
        "else:\n",
        "    print(\"â­ï¸ Local environment detected. Skipping installation.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tafK7hNo67Oa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.NaN = np.nan  # Fix missing alias\n",
        "import pandas_ta as ta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4RRkrVr67Ob",
        "outputId": "30f78b41-011b-44cb-f5fd-e1b1f4f0b6d0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Detect environment and set project path\n",
        "def is_colab():\n",
        "    return \"COLAB_GPU\" in os.environ\n",
        "\n",
        "def is_kaggle():\n",
        "    return \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ\n",
        "\n",
        "# Determine project path based on environment\n",
        "in_cloud_env = is_colab() or is_kaggle()\n",
        "\n",
        "if in_cloud_env:\n",
        "    # Cloud environment: Use cloned repository path\n",
        "    PROJECT_PATH = \"/content/AlgoTrading\"\n",
        "    print(f\"â˜ï¸ Cloud environment detected\")\n",
        "else:\n",
        "    # Local environment: Use current directory or set custom path\n",
        "    # You can modify this path if your project is in a different location\n",
        "    PROJECT_PATH = os.getcwd()\n",
        "    print(f\"ğŸ’» Local environment detected\")\n",
        "\n",
        "# Convert to Path object for easier manipulation\n",
        "project_path = Path(PROJECT_PATH)\n",
        "\n",
        "print(f\"ğŸ“ Project path set to: {project_path}\")\n",
        "print(f\"ğŸ“‚ Project exists: {project_path.exists()}\")\n",
        "\n",
        "# Change to project directory if it exists\n",
        "if project_path.exists():\n",
        "    os.chdir(str(project_path))\n",
        "    print(f\"âœ… Changed working directory to: {os.getcwd()}\")\n",
        "\n",
        "    # Add project path to Python path for imports\n",
        "    if str(project_path) not in sys.path:\n",
        "        sys.path.insert(0, str(project_path))\n",
        "        print(f\"âœ… Added to Python path: {project_path}\")\n",
        "\n",
        "    # Verify key directories exist\n",
        "    key_dirs = ['src', 'config', 'data']\n",
        "    for dir_name in key_dirs:\n",
        "        dir_path = project_path / dir_name\n",
        "        if dir_path.exists():\n",
        "            print(f\"âœ… Found directory: {dir_name}/\")\n",
        "        else:\n",
        "            print(f\"âš ï¸ Directory not found: {dir_name}/\")\n",
        "\n",
        "    # List contents to verify\n",
        "    print(f\"\\nğŸ“‹ Project contents:\")\n",
        "    for item in sorted(project_path.iterdir()):\n",
        "        if item.is_dir():\n",
        "            print(f\"  ğŸ“ {item.name}/\")\n",
        "        else:\n",
        "            print(f\"  ğŸ“„ {item.name}\")\n",
        "else:\n",
        "    print(f\"âŒ Project path does not exist: {project_path}\")\n",
        "    print(\"âš ï¸ You may need to modify PROJECT_PATH variable above\")\n",
        "\n",
        "# Store project path for use in other cells\n",
        "globals()['PROJECT_PATH'] = str(project_path)\n",
        "print(f\"\\nğŸ¯ PROJECT_PATH variable set: {PROJECT_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7csSXZW67Ob"
      },
      "source": [
        "## 3. Device Detection and Setup\n",
        "\n",
        "Automatically detect and configure the best available device (TPU > GPU > CPU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjFR2Tk767Ob",
        "outputId": "a21e2102-0bd2-4948-e6c1-f17567cf55d5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import logging\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Import optimized components\n",
        "from src.utils.device_manager import get_device_manager\n",
        "from src.utils.training_optimizer import get_training_optimizer\n",
        "\n",
        "# Initialize device manager\n",
        "device_manager = get_device_manager()\n",
        "device = device_manager.get_device()\n",
        "device_type = device_manager.get_device_type()\n",
        "\n",
        "# Print detailed device information\n",
        "device_manager.print_device_summary()\n",
        "\n",
        "# Initialize high-performance training optimizer\n",
        "training_optimizer = get_training_optimizer()\n",
        "performance_config = training_optimizer.get_optimized_training_config()\n",
        "\n",
        "# Print performance optimization summary\n",
        "training_optimizer.print_performance_summary()\n",
        "\n",
        "# Store optimized configuration for training\n",
        "DEVICE = device\n",
        "DEVICE_TYPE = device_type\n",
        "BATCH_SIZE = performance_config['batch_size']  # Optimized for 15GB VRAM\n",
        "GRADIENT_ACCUMULATION = performance_config['gradient_accumulation_steps']\n",
        "EFFECTIVE_BATCH_SIZE = performance_config['effective_batch_size']\n",
        "MIXED_PRECISION = performance_config['mixed_precision']\n",
        "DATALOADER_CONFIG = performance_config['dataloader_config']\n",
        "\n",
        "print(f\"\\nğŸ¯ HIGH-PERFORMANCE TRAINING CONFIGURATION:\")\n",
        "print(f\"  Device: {DEVICE}\")\n",
        "print(f\"  Batch Size: {BATCH_SIZE} (optimized for 15GB VRAM)\")\n",
        "print(f\"  Gradient Accumulation: {GRADIENT_ACCUMULATION}x\")\n",
        "print(f\"  Effective Batch Size: {EFFECTIVE_BATCH_SIZE}\")\n",
        "print(f\"  Mixed Precision: {'âœ… Enabled' if MIXED_PRECISION else 'âŒ Disabled'}\")\n",
        "print(f\"  DataLoader Workers: {DATALOADER_CONFIG['num_workers']}\")\n",
        "print(f\"  Expected Speedup: 5-10x faster than default settings\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPq4rb3U67Oc"
      },
      "source": [
        "## 4. Data Processing Pipeline\n",
        "\n",
        "Run the data processing pipeline to convert raw data into training-ready features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7HAiB8L67Oc",
        "outputId": "aef79683-938d-412e-db27-ed0b5cb9162e"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Import data processing pipeline\n",
        "from src.data_processing.pipeline import DataProcessingPipeline\n",
        "\n",
        "print(\"ğŸ”„ Initializing Data Processing Pipeline...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Initialize pipeline\n",
        "pipeline = DataProcessingPipeline()\n",
        "\n",
        "# Check if raw data exists\n",
        "raw_data_path = Path('data/raw')\n",
        "final_data_path = Path('data/final')\n",
        "\n",
        "print(f\"ğŸ“‚ Raw data path: {raw_data_path}\")\n",
        "print(f\"ğŸ“‚ Final data path: {final_data_path}\")\n",
        "\n",
        "# List raw data files\n",
        "if raw_data_path.exists():\n",
        "    raw_files = list(raw_data_path.glob(\"*.csv\"))\n",
        "    print(f\"ğŸ“„ Found {len(raw_files)} raw data files:\")\n",
        "    for file in raw_files[:5]:  # Show first 5 files\n",
        "        print(f\"  - {file.name}\")\n",
        "    if len(raw_files) > 5:\n",
        "        print(f\"  ... and {len(raw_files) - 5} more files\")\n",
        "else:\n",
        "    print(\"âš ï¸ No raw data directory found\")\n",
        "\n",
        "# Run feature generation pipeline\n",
        "print(\"\\nğŸš€ Running Feature Generation Pipeline...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "try:\n",
        "    result = pipeline.run_complete_pipeline(\n",
        "        input_dir=str(raw_data_path),\n",
        "        output_dir=str(final_data_path)\n",
        "    )\n",
        "\n",
        "    if result['success']:\n",
        "        print(\"\\nâœ… Data Processing Pipeline Completed Successfully!\")\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"ğŸ“Š Summary:\")\n",
        "        print(f\"  â€¢ Total files processed: {result.get('total_files_processed', 'Unknown')}\")\n",
        "        print(f\"  â€¢ Total rows processed: {result.get('total_rows_processed', 0):,}\")\n",
        "        print(f\"  â€¢ Processing time: {result.get('total_time_formatted', 'Unknown')}\")\n",
        "        print(f\"  â€¢ Output directory: {result.get('output_directory', 'Unknown')}\")\n",
        "\n",
        "        # List final data files\n",
        "        if final_data_path.exists():\n",
        "            final_files = list(final_data_path.glob(\"features_*.csv\"))\n",
        "            print(f\"\\nğŸ“ˆ Generated {len(final_files)} feature files:\")\n",
        "            for file in final_files:\n",
        "                print(f\"  - {file.name}\")\n",
        "    else:\n",
        "        print(f\"âŒ Data processing failed: {result.get('error', 'Unknown error')}\")\n",
        "        raise Exception(\"Data processing pipeline failed\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Pipeline execution failed: {str(e)}\")\n",
        "    # Continue anyway if some data exists\n",
        "    if final_data_path.exists() and list(final_data_path.glob(\"features_*.csv\")):\n",
        "        print(\"âš ï¸ Using existing processed data files\")\n",
        "    else:\n",
        "        raise\n",
        "\n",
        "print(\"\\nğŸ¯ Data processing complete. Ready for training!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drO9dpfp67Oc"
      },
      "source": [
        "## 5. HRM Training Configuration\n",
        "\n",
        "Configure the HRM training parameters and initialize the trainer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI_L3BLG67Od",
        "outputId": "247f7cbb-73e1-43b8-eed4-0911d6c4ae1d"
      },
      "outputs": [],
      "source": [
        "# HIGH-PERFORMANCE Training parameters for Colab/Kaggle (15GB VRAM + 12GB RAM)\n",
        "TRAINING_PARAMS = {\n",
        "    'epochs': 100,  # More epochs due to faster training\n",
        "    'save_frequency': 20,  # Save checkpoint every 20 epochs\n",
        "    'log_frequency': 5,   # Log progress every 5 epochs\n",
        "    'validation_frequency': 10,  # Validate every 10 epochs\n",
        "    'debug_mode': True,   # Disable debug mode for speed\n",
        "    'config_path': 'config/hrm_config.yaml',\n",
        "    'data_path': 'data/final',\n",
        "    'memory_efficient': False,  # Disabled - we have plenty of VRAM now\n",
        "\n",
        "    # High-performance optimizations\n",
        "    'high_performance': True,\n",
        "    'mixed_precision': MIXED_PRECISION,\n",
        "    'gradient_accumulation_steps': GRADIENT_ACCUMULATION,\n",
        "    'dataloader_config': DATALOADER_CONFIG,\n",
        "    'compile_model': True,  # PyTorch 2.0+ optimization\n",
        "\n",
        "    # Optimized for cloud environments\n",
        "    'cloud_optimized': True,\n",
        "    'vram_target': '15GB',\n",
        "    'ram_target': '12GB'\n",
        "}\n",
        "\n",
        "print(f\"\\nğŸš€ HIGH-PERFORMANCE Training Parameters (Colab/Kaggle Optimized):\")\n",
        "for key, value in TRAINING_PARAMS.items():\n",
        "    if isinstance(value, dict):\n",
        "        print(f\"  â€¢ {key}:\")\n",
        "        for subkey, subvalue in value.items():\n",
        "            print(f\"    - {subkey}: {subvalue}\")\n",
        "    else:\n",
        "        print(f\"  â€¢ {key}: {value}\")\n",
        "\n",
        "print(f\"\\nğŸ“± Device Configuration:\")\n",
        "print(f\"  â€¢ Device: {DEVICE}\")\n",
        "print(f\"  â€¢ Device Type: {DEVICE_TYPE}\")\n",
        "print(f\"  â€¢ Batch Size: {BATCH_SIZE} (8x larger for 15GB VRAM)\")\n",
        "print(f\"  â€¢ Effective Batch Size: {EFFECTIVE_BATCH_SIZE} (with gradient accumulation)\")\n",
        "\n",
        "print(f\"\\nğŸ—ï¸ HIGH-PERFORMANCE Training Architecture:\")\n",
        "print(f\"  â€¢ Multi-Data per Epoch: All instruments trained in each epoch\")\n",
        "print(f\"  â€¢ Memory Strategy: Full VRAM utilization (15GB)\")\n",
        "print(f\"  â€¢ Mixed Precision: {'FP16 Enabled' if MIXED_PRECISION else 'FP32'}\")\n",
        "print(f\"  â€¢ DataLoader Workers: {DATALOADER_CONFIG['num_workers']} (optimized for 12GB RAM)\")\n",
        "print(f\"  â€¢ Expected Performance: 5-10x faster than default settings\")\n",
        "print(f\"  â€¢ Flow: Large Batches â†’ Mixed Precision â†’ Gradient Accumulation â†’ Maximum Speed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjd5iQWo67Od"
      },
      "source": [
        "## 6. Initialize HRM Training Pipeline\n",
        "\n",
        "Initialize the HRM training pipeline with automatic device detection and parallel training support."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjYYrGZy67Od",
        "outputId": "3bd681cd-1517-4964-a0ce-217c37e027ea"
      },
      "outputs": [],
      "source": [
        "# Import the HRM trainer directly instead of using run_training pipeline\n",
        "from src.models.hrm_trainer import HRMTrainer\n",
        "import logging\n",
        "\n",
        "# Setup enhanced logging for notebook\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.StreamHandler()  # Only console output for notebook\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"ğŸš€ Initializing HRM Training Pipeline (Multi-Data per Epoch)...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "try:\n",
        "    # Initialize HRM trainer with memory-efficient multi-data training\n",
        "    trainer = HRMTrainer(\n",
        "        config_path=TRAINING_PARAMS['config_path'],\n",
        "        data_path=TRAINING_PARAMS['data_path'],\n",
        "        device=str(DEVICE),\n",
        "        debug_mode=TRAINING_PARAMS['debug_mode']  # Now False for multi-data\n",
        "    )\n",
        "\n",
        "    print(\"âœ… HRM Trainer initialized successfully!\")\n",
        "\n",
        "    # Check available instruments for multi-data training\n",
        "    from pathlib import Path\n",
        "    data_files = list(Path(TRAINING_PARAMS['data_path']).glob(\"features_*.csv\"))\n",
        "    available_instruments = [f.stem.replace('features_', '') for f in data_files]\n",
        "\n",
        "    print(f\"ğŸ“Š Available instruments: {len(available_instruments)}\")\n",
        "    print(\"ğŸ’¾ Memory-efficient training: Loading one data file at a time\")\n",
        "\n",
        "    # List available instruments\n",
        "    if available_instruments:\n",
        "        print(\"\\nğŸ“ˆ Available Training Instruments (All will be used per epoch):\")\n",
        "        for i, instrument in enumerate(available_instruments, 1):\n",
        "            print(f\"  {i}. {instrument}\")\n",
        "\n",
        "        print(f\"\\nğŸ¯ Training Architecture:\")\n",
        "        print(f\"  â€¢ Per Epoch: All {len(available_instruments)} instruments\")\n",
        "        print(f\"  â€¢ Per Instrument: Multiple episodes (1500 rows each)\")\n",
        "        print(f\"  â€¢ Memory Usage: One data file loaded at a time\")\n",
        "        print(f\"  â€¢ Training Flow: Instrument 1 â†’ All episodes â†’ Instrument 2 â†’ All episodes â†’ ... â†’ Epoch Complete\")\n",
        "    else:\n",
        "        raise ValueError(\"No instruments available for training\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to initialize HRM trainer: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    raise\n",
        "\n",
        "print(\"\\nğŸ”¥ Ready to start multi-data HRM training!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IL9sgXV267Oe"
      },
      "source": [
        "## 7. Training Loss Visualization Setup\n",
        "\n",
        "Setup real-time visualization for training metrics and loss curves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCeLUwHP67Oe",
        "outputId": "dbbc0ae8-d0c7-49d5-fc0e-1dde5ab0ba0a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import numpy as np\n",
        "from IPython.display import display, clear_output\n",
        "import threading\n",
        "import time\n",
        "\n",
        "class HRMTrainingVisualizer:\n",
        "    \"\"\"Real-time training visualization for Jupyter notebooks\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.training_history = []\n",
        "        self.loss_history = []\n",
        "        self.reward_history = []\n",
        "        self.best_reward = float('-inf')\n",
        "\n",
        "        # Setup plots\n",
        "        self.fig = None\n",
        "        self.setup_plots()\n",
        "\n",
        "    def setup_plots(self):\n",
        "        \"\"\"Initialize the plotting framework\"\"\"\n",
        "        plt.style.use('default')\n",
        "        plt.rcParams['figure.figsize'] = (15, 10)\n",
        "\n",
        "    def update_metrics(self, episode, metrics):\n",
        "        \"\"\"Update training metrics\"\"\"\n",
        "        self.training_history.append({\n",
        "            'episode': episode,\n",
        "            'total_reward': metrics.get('total_reward', 0),\n",
        "            'avg_reward': metrics.get('avg_reward', 0),\n",
        "            'total_loss': metrics.get('total_loss', 0),\n",
        "            'avg_loss': metrics.get('avg_loss', 0),\n",
        "            'steps': metrics.get('steps', 0)\n",
        "        })\n",
        "\n",
        "        self.reward_history.append(metrics.get('avg_reward', 0))\n",
        "        self.loss_history.append(metrics.get('avg_loss', 0))\n",
        "\n",
        "        if metrics.get('avg_reward', 0) > self.best_reward:\n",
        "            self.best_reward = metrics.get('avg_reward', 0)\n",
        "\n",
        "    def create_training_plots(self):\n",
        "        \"\"\"Create comprehensive training plots\"\"\"\n",
        "        if len(self.training_history) < 2:\n",
        "            return\n",
        "\n",
        "        # Create subplots\n",
        "        fig = make_subplots(\n",
        "            rows=2, cols=2,\n",
        "            subplot_titles=('Average Reward per Episode', 'Average Loss per Episode',\n",
        "                          'Total Reward Trend', 'Training Progress Summary'),\n",
        "            specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
        "                   [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
        "        )\n",
        "\n",
        "        episodes = [h['episode'] for h in self.training_history]\n",
        "\n",
        "        # Reward plot\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=episodes, y=self.reward_history,\n",
        "                      mode='lines+markers', name='Avg Reward',\n",
        "                      line=dict(color='green', width=2)),\n",
        "            row=1, col=1\n",
        "        )\n",
        "\n",
        "        # Loss plot\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=episodes, y=self.loss_history,\n",
        "                      mode='lines+markers', name='Avg Loss',\n",
        "                      line=dict(color='red', width=2)),\n",
        "            row=1, col=2\n",
        "        )\n",
        "\n",
        "        # Total reward trend\n",
        "        total_rewards = [h['total_reward'] for h in self.training_history]\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=episodes, y=total_rewards,\n",
        "                      mode='lines+markers', name='Total Reward',\n",
        "                      line=dict(color='blue', width=2)),\n",
        "            row=2, col=1\n",
        "        )\n",
        "\n",
        "        # Summary metrics\n",
        "        if len(self.reward_history) >= 10:\n",
        "            recent_avg_reward = np.mean(self.reward_history[-10:])\n",
        "            recent_avg_loss = np.mean(self.loss_history[-10:])\n",
        "        else:\n",
        "            recent_avg_reward = np.mean(self.reward_history)\n",
        "            recent_avg_loss = np.mean(self.loss_history)\n",
        "\n",
        "        # Create summary text\n",
        "        summary_text = f\"\"\"\n",
        "        ğŸ“Š Training Summary (Last 10 Episodes)\n",
        "        â€¢ Best Reward: {self.best_reward:.4f}\n",
        "        â€¢ Recent Avg Reward: {recent_avg_reward:.4f}\n",
        "        â€¢ Recent Avg Loss: {recent_avg_loss:.4f}\n",
        "        â€¢ Total Episodes: {len(self.training_history)}\n",
        "        \"\"\"\n",
        "\n",
        "        fig.add_annotation(\n",
        "            text=summary_text,\n",
        "            xref=\"paper\", yref=\"paper\",\n",
        "            x=0.75, y=0.3, xanchor='left', yanchor='top',\n",
        "            showarrow=False,\n",
        "            font=dict(size=12, family=\"monospace\"),\n",
        "            bgcolor=\"rgba(255,255,255,0.8)\",\n",
        "            bordercolor=\"black\",\n",
        "            borderwidth=1\n",
        "        )\n",
        "\n",
        "        fig.update_layout(\n",
        "            height=800,\n",
        "            title_text=\"HRM Training Progress - Real-time Monitoring\",\n",
        "            showlegend=True\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def display_current_metrics(self):\n",
        "        \"\"\"Display current training metrics\"\"\"\n",
        "        if not self.training_history:\n",
        "            return\n",
        "\n",
        "        latest = self.training_history[-1]\n",
        "\n",
        "        print(f\"\\nğŸ“ˆ Episode {latest['episode']} Results:\")\n",
        "        print(f\"  ğŸ¯ Average Reward: {latest['avg_reward']:.4f}\")\n",
        "        print(f\"  ğŸ“‰ Average Loss: {latest['avg_loss']:.4f}\")\n",
        "        print(f\"  ğŸ® Steps Completed: {latest['steps']}\")\n",
        "        print(f\"  ğŸ† Best Reward So Far: {self.best_reward:.4f}\")\n",
        "\n",
        "        if latest['avg_reward'] == self.best_reward:\n",
        "            print(\"  ğŸŒŸ NEW BEST PERFORMANCE! ğŸŒŸ\")\n",
        "\n",
        "# Initialize visualizer\n",
        "visualizer = HRMTrainingVisualizer()\n",
        "print(\"ğŸ“Š Training visualizer initialized!\")\n",
        "print(\"ğŸ“ˆ Real-time plots will be updated during training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFUhslqh67Oe"
      },
      "source": [
        "## 8. Start HRM Training\n",
        "\n",
        "Begin the HRM training process with real-time monitoring and visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626,
          "referenced_widgets": [
            "175501aabf314945bb3f13c4dd99f91d",
            "0c1dd137baba4988bcfcb01cd862ea01",
            "22646573d04e4e5d862b09ce9695f0d3",
            "2e285078e3a84456958ec6d5e96f2174",
            "7b4cbd69439e4cf6afe49d374339aa97",
            "6b913efc14964d0aba6053a40efa4187",
            "121d893bdf974d0facf05c783f226d04",
            "83f621d082474f04bb008877dbd0a515",
            "f6ab6938593b4ceaaa5c48797a07c8cb",
            "836be5d8885041afb7e4a888dc0bbcd9",
            "4d94dce272af4e40b29bdb9c090e572f"
          ]
        },
        "id": "IVFhQlD167Oe",
        "outputId": "2f3aa3c8-1ba0-40ea-d2e5-d8e1753a8b53"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from IPython.display import display, clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "print(\"ğŸš€ Starting HRM Multi-Data Training Process...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Create training progress widgets for multi-data training\n",
        "progress_bar = widgets.IntProgress(\n",
        "    value=0,\n",
        "    min=0,\n",
        "    max=100,  # Will be updated dynamically\n",
        "    description='Training:',\n",
        "    bar_style='info',\n",
        "    style={'bar_color': 'green'},\n",
        "    orientation='horizontal'\n",
        ")\n",
        "\n",
        "status_text = widgets.HTML(value=\"<b>Initializing multi-data training...</b>\")\n",
        "metrics_text = widgets.HTML(value=\"\")\n",
        "\n",
        "display(widgets.VBox([progress_bar, status_text, metrics_text]))\n",
        "\n",
        "# Custom training loop with visualization for multi-data\n",
        "class HRMTrainingMonitor:\n",
        "    def __init__(self, trainer, visualizer):\n",
        "        self.trainer = trainer\n",
        "        self.visualizer = visualizer\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def run_training_with_monitoring(self, epochs, available_instruments):\n",
        "        \"\"\"Run multi-data training with real-time monitoring\"\"\"\n",
        "\n",
        "        # Setup training with complete initialization for multi-data\n",
        "        print(f\"ğŸ”§ Setting up multi-data training for {len(available_instruments)} instruments...\")\n",
        "        print(f\"ğŸ“‹ Instruments: {available_instruments}\")\n",
        "\n",
        "        status_text.value = f\"<b>ğŸ¯ Multi-Data Training: {len(available_instruments)} instruments Ã— {epochs} epochs</b>\"\n",
        "\n",
        "        # Calculate total steps for progress bar (memory efficient)\n",
        "        total_steps = 0\n",
        "        print(\"ğŸ“Š Calculating training steps (memory efficient)...\")\n",
        "        for symbol in available_instruments:\n",
        "            # Quick data length check (memory efficient)\n",
        "            from src.utils.data_loader import DataLoader\n",
        "            temp_loader = DataLoader(final_data_dir=TRAINING_PARAMS['data_path'])\n",
        "            temp_data = temp_loader.load_final_data_for_symbol(symbol)\n",
        "            episodes_per_file = max(1, (len(temp_data) - 1) // 1500)  # 1500 = episode_length\n",
        "            total_steps += episodes_per_file\n",
        "            del temp_data  # Free memory immediately\n",
        "\n",
        "        total_steps *= epochs\n",
        "        progress_bar.max = total_steps\n",
        "\n",
        "        print(f\"ğŸ“ˆ Training Progress: {epochs} epochs Ã— {total_steps // epochs} total episodes = {total_steps} steps\")\n",
        "        print(\"ğŸ’¾ Memory-efficient: One data file loaded at a time\")\n",
        "\n",
        "        # Use the trainer's built-in multi-data training with progress monitoring\n",
        "        class ProgressCallback:\n",
        "            def __init__(self, progress_bar, status_text, metrics_text, visualizer):\n",
        "                self.progress_bar = progress_bar\n",
        "                self.status_text = status_text\n",
        "                self.metrics_text = metrics_text\n",
        "                self.visualizer = visualizer\n",
        "                self.step_count = 0\n",
        "\n",
        "            def update(self, epoch, instrument_idx, total_instruments, episode_metrics=None):\n",
        "                self.step_count += 1\n",
        "                self.progress_bar.value = self.step_count\n",
        "\n",
        "                current_instrument = available_instruments[instrument_idx] if instrument_idx < len(available_instruments) else \"Completing\"\n",
        "\n",
        "                self.status_text.value = f\"\"\"\n",
        "                <b>ğŸ“ˆ Epoch {epoch + 1}/{epochs} - Processing: {current_instrument}</b><br>\n",
        "                ğŸ“Š Instrument {instrument_idx + 1}/{total_instruments}<br>\n",
        "                ğŸ’¾ Memory: One data file loaded at a time\n",
        "                \"\"\"\n",
        "\n",
        "                if episode_metrics:\n",
        "                    self.visualizer.update_metrics(self.step_count, episode_metrics)\n",
        "\n",
        "                    self.metrics_text.value = f\"\"\"\n",
        "                    <div style=\"background-color: #f0f0f0; padding: 10px; border-radius: 5px;\">\n",
        "                    <b>ğŸ“Š Current Metrics:</b><br>\n",
        "                    ğŸ¯ Avg Reward: <span style=\"color: green;\"><b>{episode_metrics.get('avg_reward', 0):.4f}</b></span><br>\n",
        "                    ğŸ“‰ Avg Loss: <span style=\"color: red;\"><b>{episode_metrics.get('avg_loss', 0):.4f}</b></span><br>\n",
        "                    ğŸ® Steps: {episode_metrics.get('steps', 0)}<br>\n",
        "                    ğŸ† Best Reward: <span style=\"color: blue;\"><b>{self.visualizer.best_reward:.4f}</b></span>\n",
        "                    </div>\n",
        "                    \"\"\"\n",
        "\n",
        "        # Custom progress callback (simplified for now)\n",
        "        try:\n",
        "            print(\"ğŸš€ Starting multi-data training...\")\n",
        "            training_history = self.trainer.train(\n",
        "                epochs=epochs,\n",
        "                available_instruments=available_instruments,\n",
        "                save_frequency=TRAINING_PARAMS['save_frequency'],\n",
        "                log_frequency=TRAINING_PARAMS['log_frequency']\n",
        "            )\n",
        "\n",
        "            # Update visualizer with final results\n",
        "            for i, metrics in enumerate(training_history):\n",
        "                self.visualizer.update_metrics(i + 1, metrics)\n",
        "\n",
        "            # Final status update\n",
        "            status_text.value = \"<b>âœ… Multi-data training completed successfully!</b>\"\n",
        "            progress_bar.bar_style = 'success'\n",
        "\n",
        "            return training_history\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nâš ï¸ Training interrupted by user\")\n",
        "            status_text.value = \"<b>âš ï¸ Training interrupted by user</b>\"\n",
        "            progress_bar.bar_style = 'warning'\n",
        "            return self.trainer.training_history\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Training error: {str(e)}\")\n",
        "            status_text.value = f\"<b>âŒ Training error: {str(e)}</b>\"\n",
        "            progress_bar.bar_style = 'danger'\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return self.trainer.training_history\n",
        "\n",
        "# Initialize training monitor\n",
        "monitor = HRMTrainingMonitor(trainer, visualizer)\n",
        "\n",
        "# Start multi-data training\n",
        "try:\n",
        "    training_results = monitor.run_training_with_monitoring(\n",
        "        epochs=TRAINING_PARAMS['epochs'],\n",
        "        available_instruments=available_instruments  # Train on ALL instruments per epoch\n",
        "    )\n",
        "\n",
        "    print(\"\\nâœ… Multi-data training completed successfully!\")\n",
        "    print(f\"ğŸ¯ Trained on {len(available_instruments)} instruments per epoch\")\n",
        "    print(\"ğŸ’¾ Memory-efficient: One data file loaded at a time\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Training failed: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip6OZSy167Of"
      },
      "source": [
        "## 9. Training Results Analysis\n",
        "\n",
        "Analyze the training results and evaluate model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rWPrdXk67Of"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"ğŸ“Š Analyzing Training Results...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Final training visualization\n",
        "if visualizer.training_history:\n",
        "    print(\"ğŸ“ˆ Generating Final Training Report...\")\n",
        "\n",
        "    # Create comprehensive plots\n",
        "    final_fig = visualizer.create_training_plots()\n",
        "    if final_fig:\n",
        "        final_fig.update_layout(title_text=\"HRM Training Results - Final Report\")\n",
        "        final_fig.show()\n",
        "\n",
        "    # Statistical analysis\n",
        "    rewards = visualizer.reward_history\n",
        "    losses = visualizer.loss_history\n",
        "\n",
        "    print(f\"\\nğŸ“ˆ Training Statistics:\")\n",
        "    print(f\"  ğŸ¯ Total Episodes Completed: {len(rewards)}\")\n",
        "    print(f\"  ğŸ† Best Reward Achieved: {visualizer.best_reward:.4f}\")\n",
        "    print(f\"  ğŸ“Š Final Average Reward: {rewards[-1]:.4f}\")\n",
        "    print(f\"  ğŸ“‰ Final Average Loss: {losses[-1]:.4f}\")\n",
        "\n",
        "    if len(rewards) >= 20:\n",
        "        print(f\"\\nğŸ“Š Performance Trends:\")\n",
        "        early_reward = np.mean(rewards[:10])\n",
        "        late_reward = np.mean(rewards[-10:])\n",
        "        reward_improvement = late_reward - early_reward\n",
        "\n",
        "        early_loss = np.mean(losses[:10])\n",
        "        late_loss = np.mean(losses[-10:])\n",
        "        loss_improvement = early_loss - late_loss\n",
        "\n",
        "        print(f\"  ğŸ“ˆ Reward Improvement: {reward_improvement:.4f} ({reward_improvement/early_reward*100:+.1f}%)\")\n",
        "        print(f\"  ğŸ“‰ Loss Improvement: {loss_improvement:.4f} ({loss_improvement/early_loss*100:+.1f}%)\")\n",
        "\n",
        "    # Model performance analysis\n",
        "    print(f\"\\nğŸ§  Model Performance Analysis:\")\n",
        "    if len(rewards) > 0:\n",
        "        reward_variance = np.var(rewards)\n",
        "        reward_stability = 1.0 / (1.0 + reward_variance) if reward_variance > 0 else 1.0\n",
        "        print(f\"  ğŸ“Š Reward Variance: {reward_variance:.4f}\")\n",
        "        print(f\"  ğŸ¯ Training Stability: {reward_stability:.3f}\")\n",
        "\n",
        "        # Performance rating\n",
        "        if visualizer.best_reward > 0.1:\n",
        "            performance_rating = \"ğŸŒŸ Excellent\"\n",
        "        elif visualizer.best_reward > 0.05:\n",
        "            performance_rating = \"âœ… Good\"\n",
        "        elif visualizer.best_reward > 0.0:\n",
        "            performance_rating = \"âš ï¸ Fair\"\n",
        "        else:\n",
        "            performance_rating = \"âŒ Poor\"\n",
        "\n",
        "        print(f\"  ğŸ† Overall Performance: {performance_rating}\")\n",
        "\n",
        "    # Save training summary\n",
        "    summary_data = {\n",
        "        'episode': list(range(1, len(rewards) + 1)),\n",
        "        'avg_reward': rewards,\n",
        "        'avg_loss': losses,\n",
        "        'best_reward_so_far': [max(rewards[:i+1]) for i in range(len(rewards))]\n",
        "    }\n",
        "\n",
        "    df_summary = pd.DataFrame(summary_data)\n",
        "\n",
        "    # Save to CSV\n",
        "    results_dir = Path(\"training_results\")\n",
        "    results_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    csv_path = results_dir / f\"hrm_training_summary_{timestamp}.csv\"\n",
        "    df_summary.to_csv(csv_path, index=False)\n",
        "\n",
        "    print(f\"\\nğŸ’¾ Training summary saved to: {csv_path}\")\n",
        "\n",
        "    # Display final data sample\n",
        "    print(f\"\\nğŸ“‹ Training Summary (Last 10 Episodes):\")\n",
        "    print(df_summary.tail(10).to_string(index=False))\n",
        "\n",
        "else:\n",
        "    print(\"âš ï¸ No training history available\")\n",
        "\n",
        "print(\"\\nğŸ‰ Training analysis complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PomEXTd267Og"
      },
      "source": [
        "## 10. Model Evaluation and Testing\n",
        "\n",
        "Evaluate the trained HRM model on test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mWoDgJC67Og"
      },
      "outputs": [],
      "source": [
        "print(\"ğŸ”¬ Evaluating Trained HRM Model...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "try:\n",
        "    # Run model evaluation\n",
        "    if hasattr(trainer, 'model') and trainer.model is not None:\n",
        "        print(\"ğŸ§ª Running model evaluation on test episodes...\")\n",
        "        # Use first available instrument for evaluation\n",
        "        eval_instrument = available_instruments[0] if available_instruments else \"Bank_Nifty_5\"\n",
        "        print(f\"ğŸ“Š Evaluating on instrument: {eval_instrument}\")\n",
        "\n",
        "        eval_results = trainer.evaluate(\n",
        "            episodes=20,  # Evaluate on 20 test episodes\n",
        "            symbol=eval_instrument\n",
        "        )\n",
        "\n",
        "        print(\"\\nğŸ“Š Model Evaluation Results:\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        for metric, value in eval_results.items():\n",
        "            if isinstance(value, float):\n",
        "                print(f\"  ğŸ“ˆ {metric.replace('_', ' ').title()}: {value:.4f}\")\n",
        "            else:\n",
        "                print(f\"  ğŸ“ˆ {metric.replace('_', ' ').title()}: {value}\")\n",
        "\n",
        "        # Model summary\n",
        "        print(\"\\nğŸ§  HRM Model Architecture Summary:\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        model_summary = trainer.model.get_model_summary()\n",
        "\n",
        "        print(f\"  ğŸ”¢ Total Parameters: {model_summary['total_parameters']:,}\")\n",
        "        print(f\"  ğŸ“ Trainable Parameters: {model_summary['trainable_parameters']:,}\")\n",
        "        print(f\"  ğŸ§  H-Module Parameters: {model_summary['h_module_parameters']:,}\")\n",
        "        print(f\"  âš¡ L-Module Parameters: {model_summary['l_module_parameters']:,}\")\n",
        "        print(f\"  ğŸ”„ ACT Module Parameters: {model_summary['act_module_parameters']:,}\")\n",
        "        print(f\"  ğŸ“š Deep Supervision Parameters: {model_summary['deep_supervision_parameters']:,}\")\n",
        "        print(f\"  ğŸ“Š Hidden Dimension: {model_summary['hidden_dimension']}\")\n",
        "        print(f\"  ğŸ”„ H-Cycles: {model_summary['H_cycles']} | L-Cycles: {model_summary['L_cycles']}\")\n",
        "        print(f\"  ğŸ‘ï¸ H-Lookback: {model_summary['h_lookback_window']} | L-Lookback: {model_summary['l_lookback_window']}\")\n",
        "        print(f\"  ğŸ’» Device: {model_summary['device']}\")\n",
        "\n",
        "        # Checkpoint validation\n",
        "        print(\"\\nğŸ” Validating Model Checkpoints...\")\n",
        "        model_dir = Path(\"models/hrm\")\n",
        "        checkpoint_dir = Path(\"checkpoints/hrm\")\n",
        "\n",
        "        checkpoints_valid = False\n",
        "        if model_dir.exists() or checkpoint_dir.exists():\n",
        "            checkpoints_valid = True\n",
        "            print(\"âœ… Model checkpoints are valid and ready for deployment\")\n",
        "\n",
        "            # List saved models\n",
        "            if model_dir.exists():\n",
        "                model_files = list(model_dir.glob(\"*.pt\"))\n",
        "                print(f\"\\nğŸ“ Saved Models ({len(model_files)}):\")\n",
        "                for model_file in model_files:\n",
        "                    print(f\"  ğŸ’¾ {model_file.name}\")\n",
        "\n",
        "            if checkpoint_dir.exists():\n",
        "                checkpoint_files = list(checkpoint_dir.glob(\"*.pt\"))\n",
        "                print(f\"\\nğŸ“ Training Checkpoints ({len(checkpoint_files)}):\")\n",
        "                for checkpoint_file in checkpoint_files:\n",
        "                    print(f\"  ğŸ’¾ {checkpoint_file.name}\")\n",
        "        else:\n",
        "            print(\"âš ï¸ No checkpoint directories found yet\")\n",
        "\n",
        "    else:\n",
        "        print(\"âš ï¸ No trained model available for evaluation\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Evaluation failed: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"\\nğŸ¯ Model evaluation complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iINYDIkS67Og"
      },
      "source": [
        "## 11. Export Results and Model\n",
        "\n",
        "Export training results, model files, and create deployment package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlDj6a0r67Og"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"ğŸ“¦ Creating Export Package...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Create export directory\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "export_dir = Path(f\"hrm_export_{timestamp}\")\n",
        "export_dir.mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"ğŸ“ Export directory: {export_dir}\")\n",
        "\n",
        "try:\n",
        "    # 1. Copy model files\n",
        "    model_dir = Path(\"models/hrm\")\n",
        "    if model_dir.exists():\n",
        "        export_models_dir = export_dir / \"models\"\n",
        "        shutil.copytree(model_dir, export_models_dir)\n",
        "        print(f\"âœ… Models exported to: {export_models_dir}\")\n",
        "\n",
        "    # 2. Copy checkpoints\n",
        "    checkpoint_dir = Path(\"checkpoints/hrm\")\n",
        "    if checkpoint_dir.exists():\n",
        "        export_checkpoints_dir = export_dir / \"checkpoints\"\n",
        "        shutil.copytree(checkpoint_dir, export_checkpoints_dir)\n",
        "        print(f\"âœ… Checkpoints exported to: {export_checkpoints_dir}\")\n",
        "\n",
        "    # 3. Copy training results\n",
        "    results_dir = Path(\"training_results\")\n",
        "    if results_dir.exists():\n",
        "        export_results_dir = export_dir / \"training_results\"\n",
        "        shutil.copytree(results_dir, export_results_dir)\n",
        "        print(f\"âœ… Training results exported to: {export_results_dir}\")\n",
        "\n",
        "    # 4. Copy configuration\n",
        "    config_files = ['config/hrm_config.yaml']\n",
        "    export_config_dir = export_dir / \"config\"\n",
        "    export_config_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    for config_file in config_files:\n",
        "        if Path(config_file).exists():\n",
        "            shutil.copy2(config_file, export_config_dir)\n",
        "            print(f\"âœ… Config exported: {config_file}\")\n",
        "\n",
        "    # 5. Create training summary report\n",
        "    summary_report = {\n",
        "        \"training_info\": {\n",
        "            \"timestamp\": timestamp,\n",
        "            \"device_used\": str(DEVICE),\n",
        "            \"device_type\": DEVICE_TYPE,\n",
        "            \"batch_size\": BATCH_SIZE,\n",
        "            \"epochs_completed\": len(visualizer.training_history) if visualizer.training_history else 0,\n",
        "            \"selected_instrument\": available_instruments[0] if available_instruments else \"Unknown\"\n",
        "        },\n",
        "        \"training_parameters\": TRAINING_PARAMS,\n",
        "        \"performance_summary\": {\n",
        "            \"best_reward\": float(visualizer.best_reward) if visualizer.training_history else 0.0,\n",
        "            \"final_reward\": float(visualizer.reward_history[-1]) if visualizer.reward_history else 0.0,\n",
        "            \"final_loss\": float(visualizer.loss_history[-1]) if visualizer.loss_history else 0.0,\n",
        "            \"total_episodes\": len(visualizer.training_history) if visualizer.training_history else 0\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Add evaluation results if available\n",
        "    if 'eval_results' in locals():\n",
        "        summary_report[\"evaluation_results\"] = {\n",
        "            k: float(v) if isinstance(v, (int, float)) else v\n",
        "            for k, v in eval_results.items()\n",
        "        }\n",
        "\n",
        "    # Save summary report\n",
        "    summary_file = export_dir / \"training_summary.json\"\n",
        "    with open(summary_file, 'w') as f:\n",
        "        json.dump(summary_report, f, indent=2)\n",
        "    print(f\"âœ… Summary report saved: {summary_file}\")\n",
        "\n",
        "    # 6. Create README for export\n",
        "    readme_content = f\"\"\"\n",
        "# HRM Trading Model Export Package\n",
        "\n",
        "**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "**Training Device:** {DEVICE_TYPE.upper()}\n",
        "**Instrument:** {available_instruments[0] if available_instruments else 'Unknown'}\n",
        "\n",
        "## Contents\n",
        "\n",
        "- `models/` - Trained HRM models (best model: hrm_best_model.pt)\n",
        "- `checkpoints/` - Training checkpoints for resuming\n",
        "- `training_results/` - Training logs and metrics\n",
        "- `config/` - Model configuration files\n",
        "- `training_summary.json` - Complete training summary\n",
        "\n",
        "## Model Architecture\n",
        "\n",
        "- **Total Parameters:** {model_summary['total_parameters']:,} (â‰ˆ27M)\n",
        "- **Architecture:** Hierarchical Reasoning Model (HRM)\n",
        "- **H-Module Lookback:** {model_summary['h_lookback_window']} candles\n",
        "- **L-Module Lookback:** {model_summary['l_lookback_window']} candles\n",
        "- **Hidden Dimension:** {model_summary['hidden_dimension']}\n",
        "\n",
        "## Performance\n",
        "\n",
        "- **Best Reward:** {visualizer.best_reward:.4f}\n",
        "- **Episodes Completed:** {len(visualizer.training_history) if visualizer.training_history else 0}\n",
        "- **Training Status:** {'Completed' if len(visualizer.training_history) >= TRAINING_PARAMS['epochs'] else 'Partial'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2y74wzv67Og"
      },
      "source": [
        "## 12. Training Summary and Next Steps\n",
        "\n",
        "Final summary of the training process and recommendations for next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNgNiqzi67Oh"
      },
      "outputs": [],
      "source": [
        "print(\"ğŸŠ HRM TRAINING COMPLETED!\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Final summary\n",
        "total_time = time.time() - monitor.start_time if 'monitor' in locals() else 0\n",
        "\n",
        "print(f\"\\nğŸ“Š FINAL TRAINING SUMMARY:\")\n",
        "print(f\"=\" * 50)\n",
        "print(f\"ğŸ§  Model: Hierarchical Reasoning Model (HRM)\")\n",
        "print(f\"ğŸ“ˆ Instrument: {selected_instrument if 'selected_instrument' in locals() else 'Unknown'}\")\n",
        "print(f\"ğŸ’» Device: {DEVICE_TYPE.upper()} ({DEVICE})\")\n",
        "print(f\"â±ï¸ Total Training Time: {total_time/3600:.1f} hours\")\n",
        "print(f\"ğŸ¯ Episodes Completed: {len(visualizer.training_history) if visualizer.training_history else 0}/{TRAINING_PARAMS['epochs']}\")\n",
        "\n",
        "if visualizer.training_history:\n",
        "    print(f\"ğŸ† Best Performance: {visualizer.best_reward:.4f}\")\n",
        "    print(f\"ğŸ“ˆ Final Performance: {visualizer.reward_history[-1]:.4f}\")\n",
        "    print(f\"ğŸ“‰ Final Loss: {visualizer.loss_history[-1]:.4f}\")\n",
        "\n",
        "# Model specifications\n",
        "if 'model_summary' in locals():\n",
        "    print(f\"\\nğŸ§  MODEL SPECIFICATIONS:\")\n",
        "    print(f\"=\" * 50)\n",
        "    print(f\"ğŸ“Š Total Parameters: {model_summary['total_parameters']:,}\")\n",
        "    print(f\"ğŸ”„ H-Cycles: {model_summary['H_cycles']} | L-Cycles: {model_summary['L_cycles']}\")\n",
        "    print(f\"ğŸ‘ï¸ H-Lookback: {model_summary['h_lookback_window']} | L-Lookback: {model_summary['l_lookback_window']}\")\n",
        "    print(f\"ğŸ”¢ Hidden Dimension: {model_summary['hidden_dimension']}\")\n",
        "\n",
        "# Performance evaluation\n",
        "if visualizer.training_history:\n",
        "    performance_level = \"ğŸŒŸ Excellent\" if visualizer.best_reward > 0.1 else \\\n",
        "                       \"âœ… Good\" if visualizer.best_reward > 0.05 else \\\n",
        "                       \"âš ï¸ Fair\" if visualizer.best_reward > 0.0 else \\\n",
        "                       \"âŒ Needs Improvement\"\n",
        "\n",
        "    print(f\"\\nğŸ† PERFORMANCE EVALUATION: {performance_level}\")\n",
        "\n",
        "# Next steps recommendations\n",
        "print(f\"\\nğŸš€ RECOMMENDED NEXT STEPS:\")\n",
        "print(f\"=\" * 50)\n",
        "\n",
        "if visualizer.best_reward > 0.05:\n",
        "    print(f\"âœ… Model shows good performance:\")\n",
        "    print(f\"  â€¢ Deploy model for live testing\")\n",
        "    print(f\"  â€¢ Run extended evaluation on more instruments\")\n",
        "    print(f\"  â€¢ Consider ensemble with other models\")\n",
        "elif visualizer.best_reward > 0.0:\n",
        "    print(f\"âš ï¸ Model shows moderate performance:\")\n",
        "    print(f\"  â€¢ Continue training for more epochs\")\n",
        "    print(f\"  â€¢ Experiment with different hyperparameters\")\n",
        "    print(f\"  â€¢ Try different instruments or timeframes\")\n",
        "else:\n",
        "    print(f\"âŒ Model needs improvement:\")\n",
        "    print(f\"  â€¢ Check data quality and preprocessing\")\n",
        "    print(f\"  â€¢ Adjust learning rates or architecture\")\n",
        "    print(f\"  â€¢ Consider curriculum learning approach\")\n",
        "\n",
        "print(f\"\\nğŸ“ Export package available at: {export_dir if 'export_dir' in locals() else 'Not created'}\")\n",
        "\n",
        "# Additional recommendations\n",
        "print(f\"\\nğŸ’¡ ADDITIONAL RECOMMENDATIONS:\")\n",
        "print(f\"=\" * 50)\n",
        "print(f\"ğŸ“Š â€¢ Monitor model performance on different market conditions\")\n",
        "print(f\"ğŸ”„ â€¢ Implement continuous learning for market adaptation\")\n",
        "print(f\"âš ï¸ â€¢ Add robust risk management and position sizing\")\n",
        "print(f\"ğŸ“ˆ â€¢ Backtest on historical data before live deployment\")\n",
        "print(f\"ğŸ­ â€¢ Consider distributed training for larger datasets\")\n",
        "\n",
        "print(f\"\\nğŸ¯ Training session completed successfully!\")\n",
        "print(f\"ğŸ“š Refer to the HRM research paper for implementation details\")\n",
        "print(f\"ğŸ”— Paper: 'Hierarchical Reasoning Model' by Guan Wang et al.\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ğŸ‰ Thank you for using the HRM Training Notebook!\")\n",
        "print(\"=\" * 80)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c1dd137baba4988bcfcb01cd862ea01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "IntProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "Training:",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b913efc14964d0aba6053a40efa4187",
            "max": 44000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_121d893bdf974d0facf05c783f226d04",
            "value": 0
          }
        },
        "121d893bdf974d0facf05c783f226d04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": "green",
            "description_width": ""
          }
        },
        "175501aabf314945bb3f13c4dd99f91d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c1dd137baba4988bcfcb01cd862ea01",
              "IPY_MODEL_22646573d04e4e5d862b09ce9695f0d3",
              "IPY_MODEL_2e285078e3a84456958ec6d5e96f2174"
            ],
            "layout": "IPY_MODEL_7b4cbd69439e4cf6afe49d374339aa97"
          }
        },
        "22646573d04e4e5d862b09ce9695f0d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83f621d082474f04bb008877dbd0a515",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f6ab6938593b4ceaaa5c48797a07c8cb",
            "value": "<b>ğŸ¯ Multi-Data Training: 60 instruments Ã— 100 epochs</b>"
          }
        },
        "2e285078e3a84456958ec6d5e96f2174": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_836be5d8885041afb7e4a888dc0bbcd9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4d94dce272af4e40b29bdb9c090e572f",
            "value": ""
          }
        },
        "4d94dce272af4e40b29bdb9c090e572f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b913efc14964d0aba6053a40efa4187": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b4cbd69439e4cf6afe49d374339aa97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "836be5d8885041afb7e4a888dc0bbcd9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83f621d082474f04bb008877dbd0a515": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6ab6938593b4ceaaa5c48797a07c8cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
